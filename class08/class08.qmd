---
title: "Class 08: Breast Cancer Analysis Project"
author: "Maria Tavares (PID A69036242)"
format: pdf
toc: true
---
## Background

The goal of this mini-project is to explore a complete analysis using the unsupervised learning techniques covered in the last class. We will  extend what we learned by combining PCA as a preprocessing step to clustering using data that consist of measurements of cell nuclei of human breast masses.

The data itself comes from the Wisconsin Breast Cancer Diagnostic Data Set first reported by K. P. Benne and O. L. Mangasarian: “Robust Linear Programming Discrimination of Two Linearly Inseparable Sets”.

Values in this data set describe characteristics of the cell nuclei present in digitized images of a fine needle aspiration (FNA) of a breast mass.

## Data import 

The data is available as a CSV from the class website: 

```{r}
wisc.df <- read.csv("WisconsinCancer.csv", row.names = 1)
```

Make sure we do not include sample id or diagnosis columns in the data that we analyze below. 

```{r}
diagnosis <- as.factor(wisc.df$diagnosis)
wisc.data <- wisc.df [, -1]
dim(wisc.data)
```

## Exploratory data analysis

> Q1. How many observations are in this dataset?

There are `r nrow(wisc.data)` observations/samples/patients in the data set. 

> Q2. How many of the observations have a malignant diagnosis?

```{r}
sum(wisc.df$diagnosis == "M")
```

```{r}
table(wisc.df$diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
length( grep("_mean", colnames(wisc.data)) )
#or
n <- colnames(wisc.data)
inds <- grep("_mean", n)
length(inds)
```

## Principal Component Analysis

The main function in base R for PCA is called `prcomp()`. A optional argument `scale` should nearly always be switched to `scale=TRUE` for this function. 

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

Let's make our main result figure - the "PC plot" or "score plot", or "ordienation plot"... 

```{r}
wisc.pr$x
```

```{r}
library(ggplot2)

ggplot(wisc.pr$x) +
  aes(PC1, PC2, col = diagnosis) +
  geom_point()

```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

0.4427

```{r}
pr.var <- wisc.pr$sdev^2
round(pr.var / sum(pr.var), 2)
```


> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

It would take 3 because PC3 is 0.72636 cumulative variance

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

It's incredibly difficult to understand, the information is very crowded and you can't interpret it or make good inferences about the data. It's also using row and column names instead of dots. 

```{r}
plot(wisc.pr$x , col = diagnosis , 
     xlab = "PC1", ylab = "PC2")
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

There is still a cluster separating by malignancy. The y-axis spread is larger in PC2 and also there is a cleaner cut. 

```{r}
# Scatter plot observations by components 1 and 3
ggplot(wisc.pr$x) +
  aes(PC1, PC3, col = diagnosis) +
  geom_point()
```

## Variance 

```{r}
# Calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

```{r}
# Variance explained by each principal component: pve
pve <- round(pr.var / sum(pr.var), 2)

# Plot variance explained for each principal component
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

```{r}
# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

```{r}
## ggplot based graph
#install.packages("factoextra")
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```
> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC.

 -0.26085376

```{r}
wisc.pr$rotation[,1]
```

## Hierarchical clustering 

```{r}
data.scaled <- scale(wisc.data)
```

```{r}
data.dist <- dist(data.scaled)
```

```{r}
wisc.hclust <- hclust(data.dist, method = "complete")
```

> Q10. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

19

```{r}
plot(wisc.hclust)
abline(h=19, col="red", lty=2)
```


## Combining PCA and Clustering

```{r}
d <- dist( wisc.pr$x[,1:3] )
wisc.pr.hclust <- hclust(d, method="ward.D2")
plot(wisc.pr.hclust)
abline(h=70, col="red")
```
> Q12. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

ward2 because it gives 2 distinct groups.

Get my cluster membership vector 

```{r}
grps <- cutree(wisc.pr.hclust, h=70)
table(grps)
```

```{r}
table(diagnosis)
```

Make a wee "cross-table":

```{r}
table(grps, diagnosis)
```

> Q13. How well does the newly created model with four clusters separate out the two diagnoses?
 
It separates it pretty well. 

TP: 179
FP: 24
TN: 333
FN: 33

Specificity -  Did you find all the malignant? TN/(TN+FN)
Sensitivity - Did you say everything is malignant? TP/(TP+)

> Q14. How well do the hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

The combined model works much better. 

```{r}
table(cutree(wisc.hclust, k=4), diagnosis)
```

## Prediction

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

```{r}
g <- as.factor(grps)
levels(g)
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

> Q16. Which of these new patients should we prioritize for follow up based on your results?

Patient 1 because it is in the malignant cluster. 